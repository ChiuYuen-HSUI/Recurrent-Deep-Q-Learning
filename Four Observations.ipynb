{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gridworld import gameEnv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import pickle\n",
    "from skimage.color import rgb2gray\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Environment Object </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=True,size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7e5380c18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_state = env.reset()\n",
    "plt.imshow(prev_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Training Q Network </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyper-parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "FREEZE_INTERVAL = 20000 # steps\n",
    "MEMORY_SIZE = 60000 \n",
    "OUTPUT_SIZE = 4\n",
    "TOTAL_EPISODES = 10000\n",
    "MAX_STEPS = 50\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.1\n",
    "GAMMA = 0.99\n",
    "INPUT_IMAGE_DIM = 84\n",
    "PERFORMANCE_SAVE_INTERVAL = 500 # episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Dictionay Function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Experience Replay </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    \n",
    "    def __init__(self,memsize):\n",
    "        self.memsize = memsize\n",
    "        self.memory = deque(maxlen=self.memsize)\n",
    "    \n",
    "    def add_sample(self,sample):\n",
    "        self.memory.append(sample)\n",
    "    \n",
    "    def get_batch(self,size):\n",
    "        return random.sample(self.memory,k=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Frame Collector </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FrameCollector():\n",
    "    \n",
    "    def __init__(self,num_frames,img_dim):\n",
    "        self.num_frames = num_frames\n",
    "        self.img_dim = img_dim\n",
    "        self.frames = deque(maxlen=self.num_frames)\n",
    "    \n",
    "    def reset(self):\n",
    "        tmp = np.zeros((self.img_dim,self.img_dim))\n",
    "        for i in range(0,self.num_frames):\n",
    "            self.frames.append(tmp)\n",
    "    \n",
    "    def add_frame(self,frame):\n",
    "        self.frames.append(frame)\n",
    "        \n",
    "    def get_state(self):\n",
    "        return np.array(self.frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocess Images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = rgb2gray(image) # this automatically scales the color for block between 0 - 1\n",
    "    return np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7e52eba58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_prev_state = preprocess_image(prev_state)\n",
    "plt.imshow(processed_prev_state,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Build Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv_layer1): Conv2d(4, 64, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv_layer2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (conv_layer3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=6272, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,image_input_size,out_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.image_input_size = image_input_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=4,out_channels=64,kernel_size=8,stride=4) # GRAY - 1\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*128,out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512,out_features=OUTPUT_SIZE)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x,bsize):\n",
    "        x = x.view(bsize,4,self.image_input_size,self.image_input_size) # (N,Cin,H,W) batch size, input channel, height , width\n",
    "        conv_out = self.conv_layer1(x)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer2(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer3(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        out = self.fc1(conv_out.view(bsize,7*7*128))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).cuda()\n",
    "print(main_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Q Learning with Freeze Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated 60000 Samples in Episodes : 1200\n"
     ]
    }
   ],
   "source": [
    "mem = Memory(memsize=MEMORY_SIZE)\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda() # Primary Network\n",
    "target_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda() # Target Network\n",
    "frameObj = FrameCollector(img_dim=INPUT_IMAGE_DIM,num_frames=4)\n",
    "\n",
    "target_model.load_state_dict(main_model.state_dict())\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(main_model.parameters())\n",
    "\n",
    "# filling memory with transitions\n",
    "for i in range(0,int(MEMORY_SIZE/MAX_STEPS)):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    frameObj.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    step_count = 0\n",
    "    game_over = False\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        action = np.random.randint(0,4)\n",
    "        next_state,reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        mem.add_sample((prev_frames,action,reward,next_frames,game_over))\n",
    "    \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "\n",
    "print('Populated %d Samples in Episodes : %d'%(len(mem.memory),int(MEMORY_SIZE/MAX_STEPS)))\n",
    "\n",
    "\n",
    "# Algorithm Starts\n",
    "total_steps = 0\n",
    "epsilon = INITIAL_EPSILON\n",
    "loss_stat = []\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    frameObj.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        total_steps +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(prev_frames).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        total_reward += reward\n",
    "        \n",
    "        mem.add_sample((prev_frames,action,reward,next_frames,game_over))\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "        \n",
    "        if (total_steps % FREEZE_INTERVAL) == 0:\n",
    "            target_model.load_state_dict(main_model.state_dict())\n",
    "        \n",
    "        batch = mem.get_batch(size=BATCH_SIZE)\n",
    "        current_states = []\n",
    "        next_states = []\n",
    "        acts = []\n",
    "        rewards = []\n",
    "        game_status = []\n",
    "        \n",
    "        for element in batch:\n",
    "            current_states.append(element[0])\n",
    "            acts.append(element[1])\n",
    "            rewards.append(element[2])\n",
    "            next_states.append(element[3])\n",
    "            game_status.append(element[4])\n",
    "            \n",
    "        current_states = np.array(current_states)\n",
    "        next_states =  np.array(next_states)\n",
    "        rewards = np.array(rewards)\n",
    "        game_status = [not b for b in game_status]\n",
    "        game_status_bool = np.array(game_status,dtype='float') # FALSE 1, TRUE 0\n",
    "        torch_acts = torch.tensor(acts)\n",
    "        \n",
    "        Q_next = target_model.forward(torch.from_numpy(next_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_s = main_model.forward(torch.from_numpy(current_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_max_next, _ = Q_next.detach().max(dim=1)\n",
    "        Q_max_next = Q_max_next.double()\n",
    "        Q_max_next = torch.from_numpy(game_status_bool).cuda()*Q_max_next\n",
    "        \n",
    "        target_values = (rewards + (GAMMA * Q_max_next))\n",
    "        Q_s_a = Q_s.gather(dim=1,index=torch_acts.cuda().unsqueeze(dim=1)).squeeze(dim=1)\n",
    "    \n",
    "        loss = criterion(Q_s_a,target_values.float().cuda())\n",
    "        \n",
    "        # save performance measure\n",
    "        loss_stat.append(loss.item())\n",
    "        \n",
    "        # make previous grad zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back - propogate \n",
    "        loss.backward()\n",
    "        \n",
    "        # update params\n",
    "        optimizer.step()\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['loss'] = loss_stat\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='FOUR_OBSERV_NINE',obj=perf)\n",
    "    \n",
    "    #print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Loss : ',loss.item(),'Steps : ',step_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(main_model.state_dict(),'data/FOUR_OBSERV_NINE_WEIGHTS.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Testing Policy </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.load('data/FOUR_OBSERV_NINE_WEIGHTS.torch')\n",
    "main_model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Testing Policy </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm Starts\n",
    "epsilon = INITIAL_EPSILON\n",
    "FINAL_EPSILON = 0.01\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.reset()\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(prev_frames).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='FOUR_OBSERV_NINE',obj=perf)\n",
    "    \n",
    "    print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Steps : ',step_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
