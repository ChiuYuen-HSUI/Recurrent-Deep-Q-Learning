{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gridworld import gameEnv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import pickle\n",
    "from skimage.color import rgb2gray\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Environment Object </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=False,size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75476b1668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_state = env.reset()\n",
    "plt.imshow(prev_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Training Q Network </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyper-parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "FREEZE_INTERVAL = 20000 # steps\n",
    "MEMORY_SIZE = 60000 \n",
    "OUTPUT_SIZE = 4\n",
    "TOTAL_EPISODES = 10000\n",
    "MAX_STEPS = 50\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.01\n",
    "GAMMA = 0.99\n",
    "INPUT_IMAGE_DIM = 84\n",
    "PERFORMANCE_SAVE_INTERVAL = 500 # episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Dictionay Function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Experience Replay </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    \n",
    "    def __init__(self,memsize):\n",
    "        self.memsize = memsize\n",
    "        self.memory = deque(maxlen=self.memsize)\n",
    "    \n",
    "    def add_sample(self,sample):\n",
    "        self.memory.append(sample)\n",
    "    \n",
    "    def get_batch(self,size):\n",
    "        return random.sample(self.memory,k=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocess Images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = rgb2gray(image) # this automatically scales the color for block between 0 - 1\n",
    "    return np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7547615be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_prev_state = preprocess_image(prev_state)\n",
    "plt.imshow(processed_prev_state,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Build Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv_layer1): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv_layer2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (conv_layer3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,image_input_size,out_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.image_input_size = image_input_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=8,stride=4) # GRAY - 1\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=4,stride=2)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*64,out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512,out_features=OUTPUT_SIZE)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x,bsize):\n",
    "        x = x.view(bsize,1,self.image_input_size,self.image_input_size) # (N,Cin,H,W) batch size, input channel, height , width\n",
    "        conv_out = self.conv_layer1(x)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer2(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer3(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        out = self.fc1(conv_out.view(bsize,7*7*64))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).cuda()\n",
    "print(main_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Q Learning with Target Freeze </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated 200 Samples\n"
     ]
    }
   ],
   "source": [
    "mem = Memory(memsize=MEMORY_SIZE)\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda()\n",
    "target_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda()\n",
    "\n",
    "target_model.load_state_dict(main_model.state_dict())\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(main_model.parameters())\n",
    "\n",
    "# filling memory with transitions\n",
    "for i in range(0,int(MEMORY_SIZE/MAX_STEPS)):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    step_count = 0\n",
    "    game_over = False\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        action = np.random.randint(0,4)\n",
    "        next_state,reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        mem.add_sample((processed_prev_state,action,reward,processed_next_state,game_over))\n",
    "    \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "\n",
    "print('Populated %d Samples'%(len(mem.memory)))\n",
    "\n",
    "# Algorithm Starts\n",
    "total_steps = 0\n",
    "epsilon = INITIAL_EPSILON\n",
    "loss_stat = []\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        total_steps +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(processed_prev_state).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        total_reward += reward\n",
    "        \n",
    "        mem.add_sample((processed_prev_state,action,reward,processed_next_state,game_over))\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        \n",
    "        if (total_steps % FREEZE_INTERVAL) == 0:\n",
    "            target_model.load_state_dict(main_model.state_dict())\n",
    "        \n",
    "        batch = mem.get_batch(size=BATCH_SIZE)\n",
    "        current_states = []\n",
    "        next_states = []\n",
    "        acts = []\n",
    "        rewards = []\n",
    "        game_status = []\n",
    "        \n",
    "        for element in batch:\n",
    "            current_states.append(element[0])\n",
    "            acts.append(element[1])\n",
    "            rewards.append(element[2])\n",
    "            next_states.append(element[3])\n",
    "            game_status.append(element[4])\n",
    "            \n",
    "        current_states = np.array(current_states)\n",
    "        next_states =  np.array(next_states)\n",
    "        rewards = np.array(rewards)\n",
    "        game_status = [not b for b in game_status]\n",
    "        game_status_bool = np.array(game_status,dtype='float') # FALSE 1, TRUE 0\n",
    "        torch_acts = torch.tensor(acts)\n",
    "        \n",
    "        Q_next = target_model.forward(torch.from_numpy(next_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_s = main_model.forward(torch.from_numpy(current_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_max_next, _ = Q_next.detach().max(dim=1)\n",
    "        Q_max_next = Q_max_next.double()\n",
    "        Q_max_next = torch.from_numpy(game_status_bool).cuda()*Q_max_next\n",
    "        \n",
    "        target_values = (rewards + (GAMMA * Q_max_next)).cuda()\n",
    "        Q_s_a = Q_s.gather(dim=1,index=torch_acts.cuda().unsqueeze(dim=1)).squeeze(dim=1)\n",
    "    \n",
    "        loss = criterion(Q_s_a,target_values.float())\n",
    "        \n",
    "        # save performance measure\n",
    "        loss_stat.append(loss.item())\n",
    "        \n",
    "        # make previous grad zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back - propogate \n",
    "        loss.backward()\n",
    "        \n",
    "        # update params\n",
    "        optimizer.step()\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['loss'] = loss_stat\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='MDP_ENV_SIZE_NINE',obj=perf)\n",
    "    \n",
    "    #print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Loss : ',loss.item(),'Steps : ',step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(main_model.state_dict(),'data/MDP_ENV_SIZE_NINE_WEIGHTS.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Testing Policy </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.load('data/MDP_ENV_SIZE_NINE_WEIGHTS.torch')\n",
    "main_model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test Policy </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm Starts\n",
    "epsilon = INITIAL_EPSILON\n",
    "FINAL_EPSILON = 0.01\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(processed_prev_state).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        total_reward += reward\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='MDP_ENV_SIZE_NINE',obj=perf)\n",
    "    \n",
    "    print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Steps : ',step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Create Policy GIF </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Collect Frames Of an Episode Using Trained Network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward : 14\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "random.seed(110)\n",
    "np.random.seed(110)\n",
    "\n",
    "for episode in range(0,1):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frames.append(prev_state)\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            torch_x = torch.from_numpy(processed_prev_state).float().cuda()\n",
    "            model_out = main_model.forward(torch_x,bsize=1)\n",
    "            action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "        \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        frames.append(next_state)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        total_reward += reward\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "\n",
    "print('Total Reward : %d'%(total_reward)) # This should output same value which verifies seed is working correctly\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Frames to GIF </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/.conda/envs/myenv/lib/python3.6/site-packages/ipykernel/__main__.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from scipy.misc import imresize\n",
    "resized_frames = []\n",
    "for frame in frames:\n",
    "    resized_frames.append(imresize(frame,(256,256)))\n",
    "imageio.mimsave('data/GIFs/MDP_SIZE_9.gif',resized_frames,fps=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
