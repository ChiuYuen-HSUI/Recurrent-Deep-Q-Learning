{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gridworld import gameEnv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import pickle\n",
    "from skimage.color import rgb2gray\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Environment Object </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=True,size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb62cfada90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_state = env.reset()\n",
    "plt.imshow(prev_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Training Q Network </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyper-parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "FREEZE_INTERVAL = 20000 # steps\n",
    "MEMORY_SIZE = 60000 \n",
    "OUTPUT_SIZE = 4\n",
    "TOTAL_EPISODES = 10000\n",
    "MAX_STEPS = 50\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.1\n",
    "GAMMA = 0.99\n",
    "INPUT_IMAGE_DIM = 84\n",
    "PERFORMANCE_SAVE_INTERVAL = 500 # episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Dictionay Function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Experience Replay </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    \n",
    "    def __init__(self,memsize):\n",
    "        self.memsize = memsize\n",
    "        self.memory = deque(maxlen=self.memsize)\n",
    "    \n",
    "    def add_sample(self,sample):\n",
    "        self.memory.append(sample)\n",
    "    \n",
    "    def get_batch(self,size):\n",
    "        return random.sample(self.memory,k=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Frame Collector </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FrameCollector():\n",
    "    \n",
    "    def __init__(self,num_frames,img_dim):\n",
    "        self.num_frames = num_frames\n",
    "        self.img_dim = img_dim\n",
    "        self.frames = deque(maxlen=self.num_frames)\n",
    "    \n",
    "    def reset(self):\n",
    "        tmp = np.zeros((self.img_dim,self.img_dim))\n",
    "        for i in range(0,self.num_frames):\n",
    "            self.frames.append(tmp)\n",
    "    \n",
    "    def add_frame(self,frame):\n",
    "        self.frames.append(frame)\n",
    "        \n",
    "    def get_state(self):\n",
    "        return np.array(self.frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocess Images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = rgb2gray(image) # this automatically scales the color for block between 0 - 1\n",
    "    return np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb62cf192b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADLhJREFUeJzt3V2MXPV5x/Hvr14ICUljm7SWi0kxigVCVTGRlYLggpLSEhpBLqIUlEhpldY3qUraSsG0Fy2VIiVSlYSLKpIFSVGV8hKHJhYXSV2HpL1ysDFtwcbBJBBs+YUKyNsFqsPTizluF7p4zu7O7O7h//1Iq5lz5uX8j45+c15m9nlSVUhqyy8s9wAkLT2DLzXI4EsNMvhSgwy+1CCDLzXI4EsNWlTwk1yf5FCSw0m2TWpQkqYrC/0BT5JVwPeA64AjwCPALVV1YHLDkzQNM4t47XuAw1X1fYAk9wE3Aa8b/CT+TFCasqrKuOcs5lD/fOC5WdNHunmSVrjF7PF7SbIV2Drt5UjqbzHBPwpcMGt6QzfvVapqO7AdPNSXVorFHOo/AmxKsjHJ2cDNwM7JDEvSNC14j19Vp5L8MfBNYBXwxap6YmIjkzQ1C/46b0EL81BfmrppX9WXNFAGX2qQwZcaZPClBhl8qUEGX2qQwZcaZPClBhl8qUEGX2qQwZcaZPClBhl8qUEGX2qQwZcaZPClBhl8qUFjg5/ki0lOJnl81ry1SXYleaq7XTPdYUqapD57/L8Hrn/NvG3A7qraBOzupiUNxNjgV9W/Ai+8ZvZNwD3d/XuAD0x4XJKmaKHn+Ouq6lh3/ziwbkLjkbQEFt1Jp6rqTNVz7aQjrTwL3eOfSLIeoLs9+XpPrKrtVbWlqrYscFmSJmyhwd8JfLS7/1Hg65MZjqSlMLahRpJ7gWuAdwAngL8CvgY8ALwTeBb4UFW99gLgXO9lQw1pyvo01LCTjvQGYycdSXMy+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw3q00nngiQPJzmQ5Ikkt3bz7aYjDVSfmnvrgfVV9WiStwH7GDXQ+H3ghar6dJJtwJqqum3Me1l6S5qyiZTeqqpjVfVod/8nwEHgfOymIw3WvBpqJLkQuBzYQ89uOjbUkFae3lV2k7wV+A7wqap6MMlLVbV61uMvVtUZz/M91Jemb2JVdpOcBXwV+HJVPdjN7t1NR9LK0ueqfoC7gYNV9dlZD9lNRxqoPlf1rwb+DfhP4JVu9l8wOs+fVzcdD/Wl6bOTjtQgO+lImpPBlxpk8KUGGXypQQZfapDBlxpk8KUGGXypQQZfapDBlxpk8KUGGXypQQZfapDBlxo0r5p7mr6l/DfpIRrVhdFiuceXGmTwpQb1qbl3TpLvJvn3rpPOHd38jUn2JDmc5P4kZ09/uJImoc8e/2Xg2qq6DNgMXJ/kCuAzwOeq6l3Ai8DHpjdMSZPUp5NOVdVPu8mzur8CrgV2dPPtpCMNSN+6+quSPMaodv4u4Gngpao61T3lCKO2WnO9dmuSvUn2TmLAkhavV/Cr6udVtRnYALwHuKTvAqpqe1VtqaotCxyjpAmb11X9qnoJeBi4Elid5PTvADYARyc8NklT0ueq/i8lWd3dfzNwHaOOuQ8DH+yeZicdaUD6dNL5dUYX71Yx+qB4oKr+JslFwH3AWmA/8JGqennMe/mztDH85d6Z+cu98eykM0AG/8wM/nh20pE0J4MvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UoN7B70ps70/yUDdtJx1poOazx7+VUZHN0+ykIw1U34YaG4DfBe7qpoOddKTB6rvH/zzwSeCVbvo87KQjDVafuvrvB05W1b6FLMBOOtLKMzP+KVwF3JjkBuAc4BeBO+k66XR7fTvpSAPSp1vu7VW1oaouBG4GvlVVH8ZOOtJgLeZ7/NuAP0tymNE5/92TGZKkabOTzgpjJ50zs5POeHbSkTQngy81yOBLDTL4UoMMvtQggy81yOBLDTL4UoMMvtQggy81yOBLDTL4UoMMvtQggy81yOBLDTL4UoP61NwjyTPAT4CfA6eqakuStcD9wIXAM8CHqurF6QxT0iTNZ4//m1W1eVa13G3A7qraBOzupiUNwGIO9W9i1EgDbKghDUrf4Bfwz0n2JdnazVtXVce6+8eBdRMfnaSp6HWOD1xdVUeT/DKwK8mTsx+sqnq9QprdB8XWuR6TtDzmXWU3yV8DPwX+CLimqo4lWQ98u6ouHvNaS8iOYZXdM7PK7ngTqbKb5Nwkbzt9H/ht4HFgJ6NGGmBDDWlQxu7xk1wE/FM3OQP8Y1V9Ksl5wAPAO4FnGX2d98KY93J3NoZ7/DNzjz9enz2+DTVWGIN/ZgZ/PBtqSJqTwZcaZPClBhl8qUEGX2qQwZcaZPClBhl8qUEGX2pQ3//O0xLxl2laCu7xpQYZfKlBBl9qkMGXGmTwpQYZfKlBBl9qUK/gJ1mdZEeSJ5McTHJlkrVJdiV5qrtdM+3BSpqMvnv8O4FvVNUlwGXAQeykIw1Wn2KbbwceAy6qWU9OcgjLa0srzqRq7m0Enge+lGR/kru6Mtt20pEGqk/wZ4B3A1+oqsuBn/Gaw/ruSOB1O+kk2Ztk72IHK2ky+gT/CHCkqvZ00zsYfRCc6A7x6W5PzvXiqtpeVVtmddmVtMzGBr+qjgPPJTl9/v5e4AB20pEGq1dDjSSbgbuAs4HvA3/A6EPDTjrSCmMnHalBdtKRNCeDLzXI4EsNMvhSgwy+1CCDLzXI4EsNMvhSgwy+1CCDLzXI4EsNMvhSgwy+1CCDLzXI4EsNMvhSgwy+1KCxwU9ycZLHZv39OMkn7KQjDde8Sm8lWQUcBX4D+DjwQlV9Osk2YE1V3Tbm9ZbekqZsGqW33gs8XVXPAjcB93Tz7wE+MM/3krRM5hv8m4F7u/t20pEGqnfwk5wN3Ah85bWP2UlHGpb57PHfBzxaVSe6aTvpSAM1n+Dfwv8d5oOddKTB6ttJ51zgh4xaZf+om3cedtKRVhw76UgNspOOpDkZfKlBBl9qkMGXGmTwpQYZfKlBBl9qkMGXGmTwpQYZfKlBBl9qkMGXGmTwpQYZfKlBBl9qkMGXGmTwpQb1Cn6SP03yRJLHk9yb5JwkG5PsSXI4yf1dFV5JA9Cnhdb5wJ8AW6rq14BVjOrrfwb4XFW9C3gR+Ng0Byppcvoe6s8Ab04yA7wFOAZcC+zoHreTjjQgY4NfVUeBv2VUZfcY8CNgH/BSVZ3qnnYEOH9ag5Q0WX0O9dcw6pO3EfgV4Fzg+r4LsJOOtPLM9HjObwE/qKrnAZI8CFwFrE4y0+31NzDqovv/VNV2YHv3WstrSytAn3P8HwJXJHlLkjDqmHsAeBj4YPccO+lIA9K3k84dwO8Bp4D9wB8yOqe/D1jbzftIVb085n3c40tTZicdqUF20pE0J4MvNcjgSw0y+FKD+nyPP0n/Bfysu32jeAeuz0r1RloX6Lc+v9rnjZb0qj5Akr1VtWVJFzpFrs/K9UZaF5js+nioLzXI4EsNWo7gb1+GZU6T67NyvZHWBSa4Pkt+ji9p+XmoLzVoSYOf5Pokh7o6fduWctmLleSCJA8nOdDVH7y1m782ya4kT3W3a5Z7rPORZFWS/Uke6qYHW0sxyeokO5I8meRgkiuHvH2mWetyyYKfZBXwd8D7gEuBW5JculTLn4BTwJ9X1aXAFcDHu/FvA3ZX1SZgdzc9JLcCB2dND7mW4p3AN6rqEuAyRus1yO0z9VqXVbUkf8CVwDdnTd8O3L5Uy5/C+nwduA44BKzv5q0HDi332OaxDhsYheFa4CEgjH4gMjPXNlvJf8DbgR/QXbeaNX+Q24fRv70/x+jf3me67fM7k9o+S3mof3pFThtsnb4kFwKXA3uAdVV1rHvoOLBumYa1EJ8HPgm80k2fx3BrKW4Enge+1J263JXkXAa6fWrKtS69uDdPSd4KfBX4RFX9ePZjNfoYHsTXJEneD5ysqn3LPZYJmQHeDXyhqi5n9NPwVx3WD2z7LKrW5ThLGfyjwAWzpl+3Tt9KleQsRqH/clU92M0+kWR99/h64ORyjW+ergJuTPIMo0pK1zI6R17dlVGHYW2jI8CRqtrTTe9g9EEw1O3zv7Uuq+q/gVfVuuyes+Dts5TBfwTY1F2VPJvRhYqdS7j8RenqDd4NHKyqz856aCejmoMwoNqDVXV7VW2oqgsZbYtvVdWHGWgtxao6DjyX5OJu1unakIPcPky71uUSX7C4Afge8DTwl8t9AWWeY7+a0WHifwCPdX83MDov3g08BfwLsHa5x7qAdbsGeKi7fxHwXeAw8BXgTcs9vnmsx2Zgb7eNvgasGfL2Ae4AngQeB/4BeNOkto+/3JMa5MU9qUEGX2qQwZcaZPClBhl8qUEGX2qQwZcaZPClBv0PANIhuBFMr1IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_prev_state = preprocess_image(prev_state)\n",
    "plt.imshow(processed_prev_state,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Build Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv_layer1): Conv2d(2, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv_layer2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (conv_layer3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,image_input_size,out_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.image_input_size = image_input_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=2,out_channels=32,kernel_size=8,stride=4) # GRAY - 1\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=4,stride=2)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*64,out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512,out_features=OUTPUT_SIZE)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x,bsize):\n",
    "        x = x.view(bsize,2,self.image_input_size,self.image_input_size) # (N,Cin,H,W) batch size, input channel, height , width\n",
    "        conv_out = self.conv_layer1(x)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer2(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer3(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        out = self.fc1(conv_out.view(bsize,7*7*64))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).cuda()\n",
    "print(main_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Q Learning with Freeze Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated 60000 Samples in Episodes : 1200\n"
     ]
    }
   ],
   "source": [
    "mem = Memory(memsize=MEMORY_SIZE)\n",
    "main_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda() # Primary Network\n",
    "target_model = Network(image_input_size=INPUT_IMAGE_DIM,out_size=OUTPUT_SIZE).float().cuda() # Target Network\n",
    "frameObj = FrameCollector(img_dim=INPUT_IMAGE_DIM,num_frames=2)\n",
    "\n",
    "target_model.load_state_dict(main_model.state_dict())\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(main_model.parameters())\n",
    "\n",
    "# filling memory with transitions\n",
    "for i in range(0,int(MEMORY_SIZE/MAX_STEPS)):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    frameObj.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    step_count = 0\n",
    "    game_over = False\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        action = np.random.randint(0,4)\n",
    "        next_state,reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        mem.add_sample((prev_frames,action,reward,next_frames,game_over))\n",
    "    \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "\n",
    "print('Populated %d Samples in Episodes : %d'%(len(mem.memory),int(MEMORY_SIZE/MAX_STEPS)))\n",
    "\n",
    "\n",
    "# Algorithm Starts\n",
    "total_steps = 0\n",
    "epsilon = INITIAL_EPSILON\n",
    "loss_stat = []\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    frameObj.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        total_steps +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(prev_frames).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        total_reward += reward\n",
    "        \n",
    "        mem.add_sample((prev_frames,action,reward,next_frames,game_over))\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "        \n",
    "        if (total_steps % FREEZE_INTERVAL) == 0:\n",
    "            target_model.load_state_dict(main_model.state_dict())\n",
    "        \n",
    "        batch = mem.get_batch(size=BATCH_SIZE)\n",
    "        current_states = []\n",
    "        next_states = []\n",
    "        acts = []\n",
    "        rewards = []\n",
    "        game_status = []\n",
    "        \n",
    "        for element in batch:\n",
    "            current_states.append(element[0])\n",
    "            acts.append(element[1])\n",
    "            rewards.append(element[2])\n",
    "            next_states.append(element[3])\n",
    "            game_status.append(element[4])\n",
    "            \n",
    "        current_states = np.array(current_states)\n",
    "        next_states =  np.array(next_states)\n",
    "        rewards = np.array(rewards)\n",
    "        game_status = [not b for b in game_status]\n",
    "        game_status_bool = np.array(game_status,dtype='float') # FALSE 1, TRUE 0\n",
    "        torch_acts = torch.tensor(acts)\n",
    "        \n",
    "        Q_next = target_model.forward(torch.from_numpy(next_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_s = main_model.forward(torch.from_numpy(current_states).float().cuda(),bsize=BATCH_SIZE)\n",
    "        Q_max_next, _ = Q_next.detach().max(dim=1)\n",
    "        Q_max_next = Q_max_next.double()\n",
    "        Q_max_next = torch.from_numpy(game_status_bool).cuda()*Q_max_next\n",
    "        \n",
    "        target_values = (rewards + (GAMMA * Q_max_next))\n",
    "        Q_s_a = Q_s.gather(dim=1,index=torch_acts.cuda().unsqueeze(dim=1)).squeeze(dim=1)\n",
    "    \n",
    "        loss = criterion(Q_s_a,target_values.float().cuda())\n",
    "        \n",
    "        # save performance measure\n",
    "        loss_stat.append(loss.item())\n",
    "        \n",
    "        # make previous grad zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back - propogate \n",
    "        loss.backward()\n",
    "        \n",
    "        # update params\n",
    "        optimizer.step()\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['loss'] = loss_stat\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='TWO_OBSERV_NINE',obj=perf)\n",
    "    \n",
    "    #print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Loss : ',loss.item(),'Steps : ',step_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(main_model.state_dict(),'data/TWO_OBSERV_NINE_WEIGHTS.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Testing Policy </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Primary Network Weights </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('data/TWO_OBSERV_NINE_WEIGHTS.torch')\n",
    "main_model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Testing Policy </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm Starts\n",
    "epsilon = INITIAL_EPSILON\n",
    "FINAL_EPSILON = 0.01\n",
    "total_reward_stat = []\n",
    "\n",
    "for episode in range(0,TOTAL_EPISODES):\n",
    "    \n",
    "    prev_state = env.reset()\n",
    "    processed_prev_state = preprocess_image(prev_state)\n",
    "    frameObj.reset()\n",
    "    frameObj.add_frame(processed_prev_state)\n",
    "    prev_frames = frameObj.get_state()\n",
    "    game_over = False\n",
    "    step_count = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while (game_over == False) and (step_count < MAX_STEPS):\n",
    "        \n",
    "        step_count +=1\n",
    "        \n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0,4)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                torch_x = torch.from_numpy(prev_frames).float().cuda()\n",
    "\n",
    "                model_out = main_model.forward(torch_x,bsize=1)\n",
    "                action = int(torch.argmax(model_out.view(OUTPUT_SIZE),dim=0))\n",
    "                \n",
    "        next_state, reward, game_over = env.step(action)\n",
    "        processed_next_state = preprocess_image(next_state)\n",
    "        frameObj.add_frame(processed_next_state)\n",
    "        next_frames = frameObj.get_state()\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        prev_state = next_state\n",
    "        processed_prev_state = processed_next_state\n",
    "        prev_frames = next_frames\n",
    "    \n",
    "    # save performance measure\n",
    "    total_reward_stat.append(total_reward)\n",
    "    \n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/TOTAL_EPISODES\n",
    "    \n",
    "    if (episode + 1)% PERFORMANCE_SAVE_INTERVAL == 0:\n",
    "        perf = {}\n",
    "        perf['total_reward'] = total_reward_stat\n",
    "        save_obj(name='TWO_OBSERV_NINE',obj=perf)\n",
    "    \n",
    "    print('Completed episode : ',episode+1,' Epsilon : ',epsilon,' Reward : ',total_reward,'Steps : ',step_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
